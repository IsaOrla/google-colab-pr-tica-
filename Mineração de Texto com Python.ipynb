{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNi4OQIQTP/e16Qzs4WpRzD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip3 install --user nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BV494K__rLAc","executionInfo":{"status":"ok","timestamp":1693503540311,"user_tz":180,"elapsed":5204,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"4217f196-03a3-4a15-84c0-1d0dc36e78a8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]}]},{"cell_type":"code","source":["! pip3 install --user feedparser python3\n","import nltk\n","nltk.download(\"all\")\n","quit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KqGwOwRreKR","executionInfo":{"status":"ok","timestamp":1693503667818,"user_tz":180,"elapsed":57620,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"eeffd449-b22b-48df-fb6b-de9e78bc9750"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: feedparser in /root/.local/lib/python3.10/site-packages (6.0.10)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement python3 (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for python3\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"mxUGuV_xqmmT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693503707816,"user_tz":180,"elapsed":1489,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"f6f9f0f4-938b-4c5b-913e-ea822d0582ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Radicais das palavras em ingles:\n","caress fli die mule deni die agre own humbl size meet state siez item sensat tradit refer colon plot\n","Idiomas disponiveis:\n","arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n","Radicais das palavras em portugues:\n","entreg\n","livr\n","feliz\n","infeliz\n"]}],"source":["import nltk\n","from nltk.stem import *\n","from nltk.stem.porter import *\n","from nltk.stem.snowball import SnowballStemmer\n","#Criando um novo \"Porter Stemmer\"\n","stemmer = PorterStemmer()\n","#Criando a lista de palavras no plural para testar o stemmer\n","plurals = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', 'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', 'traditional', 'reference', 'colonizer','plotted']\n","# Chamando a função que encontra os radicais\n","singles = [stemmer.stem(plural) for plural in plurals]\n","print(\"Radicais das palavras em ingles:\")\n","print(' '.join(singles))\n","# verificando os idiomas disponíveis para utilizar a ferramenta stemmer\n","print(''\"Idiomas disponiveis:\")\n","print(\" \".join(SnowballStemmer.languages))\n","# trocando o idioma para português\n","stemmer2 = SnowballStemmer(\"portuguese\", ignore_stopwords=True)\n","print(\"Radicais das palavras em portugues:\")\n","print(stemmer2.stem(\"entregar\"))\n","print(stemmer2.stem(\"livre\"))\n","print(stemmer2.stem(\"feliz\"))\n","print(stemmer2.stem(\"infeliz\"))"]},{"cell_type":"code","source":["#importando as libs utilizadas\n","import nltk\n","from nltk.tree import *\n","from nltk.corpus import wordnet as wn\n","#criando as árvores para teste\n","dp1 = Tree('dp', [Tree('d', ['o']), Tree('np', ['cachorro'])])\n","dp2 = Tree('dp', [Tree('d', ['o']), Tree('np', ['gato'])])\n","vp = Tree('vp', [Tree('v', ['perseguiu']), dp2])\n","tree = Tree('s', [dp1, vp])\n","print(tree)\n","#acessando a label do nó usando o método label()\n","dp1.label(), dp2.label(), vp.label(), tree.label()\n","#O método treepositions retorna uma lista das posições da árvore de sub árvores e folhas em uma árvore. Por padrão, ele fornece a posição de cada árvore, subárvore e folha, ordenando pelo prefixo\n","print(tree.treepositions())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNqqwGM2w6VR","executionInfo":{"status":"ok","timestamp":1693505008743,"user_tz":180,"elapsed":415,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"6863106b-1d4a-444e-c6b2-1e139b34ade2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["(s (dp (d o) (np cachorro)) (vp (v perseguiu) (dp (d o) (np gato))))\n","[(), (0,), (0, 0), (0, 0, 0), (0, 1), (0, 1, 0), (1,), (1, 0), (1, 0, 0), (1, 1), (1, 1, 0), (1, 1, 0, 0), (1, 1, 1), (1, 1, 1, 0)]\n"]}]},{"cell_type":"code","source":["#Além de str e repr, existem vários métodos para converter um objeto de árvore em uma das várias codificações de árvores possíveis:\n","print(\"Árvore em Formato latex\")\n","print(tree.pformat_latex_qtree())\n","print(\"Árvore em formato ASCII\")\n","print(tree.pretty_print())\n","print(\"Árvore no formato de chaves\")\n","print(tree.pretty_print(unicodelines=True, nodedist=4))\n","#O método de classe Tree.fromlist() pode ser usado para analisar árvores expressas como listas aninhadas, como aquelas produzidas pela função tree() do módulo wordnet.\n","t=Tree.fromlist(wn.synset('dog.n.01').tree(lambda s:s.hypernyms()))\n","print(\"Método Tree.formlis()\")\n","print(t.pretty_print())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pc4YlSPrw71a","executionInfo":{"status":"ok","timestamp":1693505049493,"user_tz":180,"elapsed":1025,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"ceeecfec-8317-4f86-bf30-4e981b44490b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Árvore em Formato latex\n","\\Tree [.s\n","        [.dp [.d o ] [.np cachorro ] ]\n","        [.vp [.v perseguiu ] [.dp [.d o ] [.np gato ] ] ] ]\n","Árvore em formato ASCII\n","                     s                 \n","      _______________|______            \n","     |                      vp         \n","     |                ______|___        \n","     dp              |          dp     \n","  ___|_____          |       ___|___    \n"," d         np        v      d       np \n"," |         |         |      |       |   \n"," o      cachorro perseguiu  o      gato\n","\n","None\n","Árvore no formato de chaves\n","                              s                          \n","        ┌─────────────────────┴─────────┐                    \n","        │                               vp               \n","        │                     ┌─────────┴──────┐             \n","        dp                    │                dp        \n"," ┌──────┴────────┐            │         ┌──────┴──────┐      \n"," d               np           v         d             np \n"," │               │            │         │             │      \n"," o            cachorro    perseguiu     o            gato\n","\n","None\n","Método Tree.formlis()\n","                  Synset('dog.n.01')                  \n","         _________________|__________________          \n","Synset('canine.n.                            |        \n","       02')                                  |        \n","        |                                    |         \n"," Synset('carnivor                            |        \n","     e.n.01')                                |        \n","        |                                    |         \n"," Synset('placenta                            |        \n","     l.n.01')                                |        \n","        |                                    |         \n","Synset('mammal.n.                            |        \n","       01')                                  |        \n","        |                                    |         \n"," Synset('vertebra                            |        \n","    te.n.01')                                |        \n","        |                                    |         \n","Synset('chordate.                     Synset('domestic\n","      n.01')                           _animal.n.01') \n","        |                                    |         \n","Synset('animal.n.                    Synset('animal.n.\n","       01')                                 01')      \n","        |                                    |         \n","Synset('organism.                    Synset('organism.\n","      n.01')                               n.01')     \n","        |                                    |         \n"," Synset('living_t                     Synset('living_t\n","   hing.n.01')                          hing.n.01')   \n","        |                                    |         \n"," Synset('whole.n.                     Synset('whole.n.\n","       02')                                 02')      \n","        |                                    |         \n","Synset('object.n.                    Synset('object.n.\n","       01')                                 01')      \n","        |                                    |         \n"," Synset('physical                     Synset('physical\n","  _entity.n.01')                       _entity.n.01') \n","        |                                    |         \n","Synset('entity.n.                    Synset('entity.n.\n","       01')                                 01')      \n","\n","None\n"]}]},{"cell_type":"code","source":["#importando o corpus\n","import nltk\n","from nltk.corpus import floresta\n","#exibindo o dataset retirado de https://www.linguateca.pt/Floresta/\n","print(\"Corpus sem tratamento\",floresta.words())\n","#Exibindo o corpus com informações sintáticas\n","print(\"Corpus com sinalização Sintática\",floresta.tagged_words())\n","\n","#simplificando as informações sintáticas\n","def simplify_tag(t):\n","    if \"+\" in t:\n","        return t[t.index(\"+\")+1:]\n","    else:\n","        return t\n","twords = floresta.tagged_words()\n","twords = [(w.lower(), simplify_tag(t)) for (w,t) in twords]\n","print(\"Corpus com as sinalizações simplificadas\",twords[:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7LgQfs16HT5","executionInfo":{"status":"ok","timestamp":1693507453536,"user_tz":180,"elapsed":4395,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"b65431a0-6a52-4444-ea67-f3c2c845fd88"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus sem tratamento ['Um', 'revivalismo', 'refrescante', 'O', '7_e_Meio', ...]\n","Corpus com sinalização Sintática [('Um', '>N+art'), ('revivalismo', 'H+n'), ...]\n","Corpus com as sinalizações simplificadas [('um', 'art'), ('revivalismo', 'n'), ('refrescante', 'adj'), ('o', 'art'), ('7_e_meio', 'prop'), ('é', 'v-fin'), ('um', 'art'), ('ex-libris', 'n'), ('de', 'prp'), ('a', 'art'), ('noite', 'n'), ('algarvia', 'adj'), ('.', '.'), ('é', 'v-fin'), ('uma', 'num'), ('de', 'prp'), ('as', 'art'), ('mais', 'adv'), ('antigas', 'adj'), ('discotecas', 'n'), ('de', 'prp'), ('o', 'art'), ('algarve', 'prop'), (',', ','), ('situada', 'v-pcp'), ('em', 'prp'), ('albufeira', 'prop'), (',', ','), ('que', 'pron-indp'), ('continua', 'v-fin'), ('a', 'prp'), ('manter', 'v-inf'), ('os', 'art'), ('traços', 'n'), ('decorativos', 'adj'), ('e', 'conj-c'), ('as', 'art'), ('clientelas', 'n'), ('de', 'prp'), ('sempre', 'adv'), ('.', '.'), ('é', 'v-fin'), ('um_pouco', 'adv'), ('a', 'art'), ('versão', 'n'), ('de', 'prp'), ('uma', 'art'), ('espécie', 'n'), ('de', 'prp'), ('«', '«'), ('outro', 'pron-det'), ('lado', 'n'), ('de', 'prp'), ('a', 'art'), ('noite', 'n'), (',', ','), ('a', 'prp'), ('meio', 'adj'), ('caminho', 'n'), ('entre', 'prp'), ('os', 'art'), ('devaneios', 'n'), ('de', 'prp'), ('uma', 'art'), ('fauna', 'n'), ('periférica', 'adj'), (',', ','), ('seja', 'v-fin'), ('de', 'prp'), ('lisboa', 'prop'), (',', ','), ('londres', 'prop'), (',', ','), ('dublin', 'prop'), ('ou', 'conj-c'), ('faro', 'n'), ('e', 'conj-c'), ('portimão', 'prop'), (',', ','), ('e', 'conj-c'), ('a', 'art'), ('postura', 'n'), ('circunspecta', 'adj'), ('de', 'prp'), ('os', 'art'), ('fiéis', 'n'), ('de', 'prp'), ('a', 'art'), ('casa', 'n'), (',', ','), ('que', 'pron-indp'), ('de', 'prp'), ('ela', 'pron-pers'), ('esperam', 'v-fin'), ('a', 'art'), ('música', 'n'), ('«', '«'), ('geracionista', 'n'), ('de', 'prp'), ('os', 'art')]\n"]}]},{"cell_type":"code","source":["# importando os módulos\n","import nltk\n","import random\n","\n","#Vamos criar uma função para filtrar os significantes de gênero\n","def gender_features(name):\n","   name = name.lower()\n","   return {\n","       'ultimo_caractere': name[-1],\n","       'ultimos_dois': name[-2:],\n","       'ultimos_tres': name[-3:],\n","       'primeiro_caractere': name[0],\n","       'segundo_caractere': name[:1]\n","   }\n","\n","#Vamos preparar os a lista de nomes para serem classificados\n","f_names = nltk.corpus.names.words('female.txt')\n","m_names = nltk.corpus.names.words('male.txt')\n","#Em seguida, usamos o extrator de recursos para processar os nomes e dividir a lista resultante em um conjunto de treinamento e um conjunto de testes.\n","all_names = [(i, 'masculino') for i in m_names] + [(i, 'feminino') for i in f_names]\n","random.shuffle(all_names)\n","test_set = all_names[500:]\n","train_set= all_names[:500]\n","\n","test_set_feat = [(gender_features(n), g) for n, g in test_set]\n","train_set_feat= [(gender_features(n), g) for n, g in train_set]\n","# O conjunto de treinamento é usado para treinar um novo classificador do tipo \"naive Bayes\".\n","classifier = nltk.NaiveBayesClassifier.train(train_set_feat)\n","print(\"Maria é do genero: \",classifier.classify(gender_features('Maria')))\n","print(\"João é do gênero: \",classifier.classify(gender_features('João')))\n","# Observe que esses nomes estão classificados corretamente.\n","#Por fim, podemos examinar o classificador para determinar quais recursos ele achou mais eficazes para distinguir os gêneros dos nomes\n","# print (classifier.show_most_informative_features(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeVn7fEB-uoA","executionInfo":{"status":"ok","timestamp":1693508690058,"user_tz":180,"elapsed":357,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"566e5f34-7793-48da-b723-bc50ba2f8271"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Maria é do genero:  feminino\n","João é do gênero:  masculino\n"]}]},{"cell_type":"code","source":["print(\"Isabella é do genero: \",classifier.classify(gender_features('Isabella')))\n","print(\"Guilherme é do gênero: \",classifier.classify(gender_features('Guilherme')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sT0B2T6t_HGi","executionInfo":{"status":"ok","timestamp":1693508819959,"user_tz":180,"elapsed":415,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"5fecf45e-c458-4b8b-ac52-ef08a564e274"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Isabella é do genero:  feminino\n","Guilherme é do gênero:  masculino\n"]}]},{"cell_type":"code","source":["print(\"Maria é do genero: \",classifier.classify(gender_features('Maria')))\n","print(\"Fernanda é do gênero: \",classifier.classify(gender_features('Fernanda')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jhNjgJR_MgU","executionInfo":{"status":"ok","timestamp":1693508866384,"user_tz":180,"elapsed":348,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"bc2438e9-5a6c-4763-c31d-d9a5c2fb8264"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Maria é do genero:  feminino\n","Fernanda é do gênero:  feminino\n"]}]},{"cell_type":"code","source":["print(\"Neo é do genero: \",classifier.classify(gender_features('Neo')))\n","print(\"Morpheus é do gênero: \",classifier.classify(gender_features('Morpheus')))\n","print(\"Smith é do genero: \",classifier.classify(gender_features('Smith')))\n","print(\"Afrodite é do gênero: \",classifier.classify(gender_features('Afrodite')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soNcB-41DJrx","executionInfo":{"status":"ok","timestamp":1693509845990,"user_tz":180,"elapsed":463,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"4c814fb8-ca01-47a9-fca1-87375210e744"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Neo é do genero:  masculino\n","Morpheus é do gênero:  masculino\n","Smith é do genero:  masculino\n","Afrodite é do gênero:  feminino\n"]}]},{"cell_type":"code","source":["gender_features(\"Felipe\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DF0W99XX_3js","executionInfo":{"status":"ok","timestamp":1693508940079,"user_tz":180,"elapsed":425,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"021b4f11-0c9f-4af9-d2cd-bbf268b5e83f"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ultimo_caractere': 'e',\n"," 'ultimos_dois': 'pe',\n"," 'ultimos_tres': 'ipe',\n"," 'primeiro_caractere': 'f',\n"," 'segundo_caractere': 'f'}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print (classifier.show_most_informative_features(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npeohyQDAISO","executionInfo":{"status":"ok","timestamp":1693508999669,"user_tz":180,"elapsed":4,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"8fecd17e-51f2-40b9-804a-fc53690c28b0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Most Informative Features\n","        ultimo_caractere = 'a'            femini : mascul =     31.4 : 1.0\n","        ultimo_caractere = 'r'            mascul : femini =     10.9 : 1.0\n","        ultimo_caractere = 'o'            mascul : femini =     10.3 : 1.0\n","            ultimos_dois = 'ne'           femini : mascul =      7.1 : 1.0\n","            ultimos_dois = 'us'           mascul : femini =      6.9 : 1.0\n","            ultimos_dois = 'ra'           femini : mascul =      5.6 : 1.0\n","            ultimos_tres = 'ine'          femini : mascul =      5.5 : 1.0\n","        ultimo_caractere = 'k'            mascul : femini =      5.4 : 1.0\n","        ultimo_caractere = 'm'            mascul : femini =      5.4 : 1.0\n","        ultimo_caractere = 's'            mascul : femini =      5.2 : 1.0\n","None\n"]}]},{"cell_type":"code","source":["#importando as libs utilizadas\n","import nltk\n","from urllib import request\n","from nltk.tokenize import word_tokenize\n","#definindo a URL que contém o livro \"A Relíquia\" de Eça de Queirós\n","url = \"https://www.gutenberg.org/cache/epub/17515/pg17515.txt\"\n","#Fazendo a requisição do livro definindo disponível no acervo online\n","response = request.urlopen(url)\n","#Decodificando o corpus para o formato UTF8\n","raw = response.read().decode('utf8')\n","#criando a lista de tokens\n","tokens = word_tokenize(raw)\n","#Exibindo as informações do arquivo\n","print(\"Tipo de dado dos tokens\",type(tokens))\n","print(\"Tamanho do corpus do token\", len(tokens))\n","print(\"Uma fatia do conteúdo do token\", tokens[:12])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XHU2cm5CgkR","executionInfo":{"status":"ok","timestamp":1693509629240,"user_tz":180,"elapsed":6516,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"d83d760c-b44c-43e1-c1b8-6df13109bfa4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Tipo de dado dos tokens <class 'list'>\n","Tamanho do corpus do token 103323\n","Uma fatia do conteúdo do token ['\\ufeff', 'The', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Relíquia', 'This', 'ebook', 'is', 'for']\n"]}]},{"cell_type":"code","source":["type(raw)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mza9ZCrVCmTB","executionInfo":{"status":"ok","timestamp":1693509651034,"user_tz":180,"elapsed":411,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"a67558f3-a005-4605-ba45-17ba6045c735"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#importando as libs utilizadas\n","import nltk\n","from urllib import request\n","from nltk.tokenize import word_tokenize\n","#definindo a URL que contém o livro \"A Relíquia\" de Eça de Queirós\n","url = \"https://www.gutenberg.org/cache/epub/17515/pg17515.txt\"\n","#Fazendo a requisição do livro definindo disponível no acervo online\n","response = request.urlopen(url)\n","#Decodificando o corpus para o formato UTF8\n","raw = response.read().decode('utf8')\n","#criando a lista de tokens\n","tokens = word_tokenize(raw)\n","#Criando um corpus NLTK\n","text = nltk.Text(tokens)\n","#Exibindo as informações do arquivo\n","print(\"Tipo de dado dos tokens\",type(tokens))\n","print(\"Tipo de dado dos text\",type(text))\n","print(\"Uma fatia do conteúdo do token\", tokens[150:200])\n","print(\"Exibindo o corpus criado\", text[150:200])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9iuihgBCxSc","executionInfo":{"status":"ok","timestamp":1693509698647,"user_tz":180,"elapsed":6137,"user":{"displayName":"Isabella Orlando","userId":"14405721422426458542"}},"outputId":"9b350478-c3a1-49a9-bbf3-cc35f8745ecb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Tipo de dado dos tokens <class 'list'>\n","Tipo de dado dos text <class 'nltk.text.Text'>\n","Uma fatia do conteúdo do token ['was', 'produced', 'from', 'images', 'generously', 'made', 'available', 'by', 'National', 'Library', 'of', 'Portugal', '(', 'Biblioteca', 'Nacional', 'de', 'Portugal', ')', '.', ')', 'A', 'RELIQUIA', '*', 'A', 'Reliquia', '*', 'Decidi', 'compôr', ',', 'nos', 'vagares', \"d'este\", 'verão', ',', 'na', 'minha', 'quinta', 'do', '_Mosteiro_', '(', 'antigo', 'solar', 'dos', 'condes', 'de', 'Landoso', ')', 'as', 'memorias', 'da']\n","Exibindo o corpus criado ['was', 'produced', 'from', 'images', 'generously', 'made', 'available', 'by', 'National', 'Library', 'of', 'Portugal', '(', 'Biblioteca', 'Nacional', 'de', 'Portugal', ')', '.', ')', 'A', 'RELIQUIA', '*', 'A', 'Reliquia', '*', 'Decidi', 'compôr', ',', 'nos', 'vagares', \"d'este\", 'verão', ',', 'na', 'minha', 'quinta', 'do', '_Mosteiro_', '(', 'antigo', 'solar', 'dos', 'condes', 'de', 'Landoso', ')', 'as', 'memorias', 'da']\n"]}]}]}